{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==贝叶斯公式 拼写检查==\n",
    "#==需求：输入一个写错的单词，提示一个可能正确的==\n",
    "#原理：用先验的已经存在词库中的词频来算出现这个词的概率，\n",
    "#比较其它词，选一个可能性最大的给提示出来\n",
    "\n",
    "import re, collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function train.<locals>.<lambda> at 0x000000F1C85BAF28>, {'a': 41, 'simple': 2, 'illustration': 3, 'of': 49, 'the': 63, 'clash': 2, 'and': 40, 'confusion': 2, 'two': 4, 'opposing': 4, 'systems': 6, 'memories': 4, 'in': 31, 'dreams': 11, 'when': 4, 'due': 2, 'apperceptive': 2, 'control': 2, 'is': 15, 'lacking': 2, 'supplied': 2, 'by': 7, 'common': 2, 'well': 2, 'recognised': 2, 'type': 4, 'dream': 18, 'returning': 3, 'to': 35, 'school': 5, 'youth': 2, 'many': 2, 'people': 2, 'are': 6, 'occasionally': 2, 'liable': 2, 'this': 9, 'which': 11, 'often': 3, 'vivid': 4, 'disturbing': 2, 'we': 5, 'may': 4, 'have': 5, 'left': 2, 'schoolroom': 2, 'thirty': 3, 'years': 3, 'or': 4, 'more': 7, 'ago': 2, 'never': 2, 'seen': 3, 'it': 12, 'since': 3, 'vanished': 2, 'from': 7, 'our': 7, 'waking': 2, 'thoughts': 2, 'yet': 5, 'time': 7, 'find': 3, 'ourselves': 2, 'there': 7, 'called': 2, 'upon': 3, 'take': 3, 'old': 8, 'place': 4, 'always': 2, 'with': 6, 'sense': 4, 'conflict': 2, 'vague': 2, 'discomfort': 2, 'feeling': 5, 'something': 2, 'incongruous': 3, 'humiliating': 2, 'for': 5, 'realise': 3, 'that': 32, 'now': 2, 'too': 2, 'here': 3, 'i': 25, 'myself': 3, 'back': 2, 'at': 7, 'my': 9, 'but': 10, 'schoolmaster': 2, 'not': 9, 'he': 11, 'away': 3, 'ill': 2, 'as': 10, 'am': 4, 'told': 4, 'his': 15, 'substitute': 2, 'whose': 2, 'face': 2, 'somehow': 4, 'seems': 4, 'familiar': 2, 'though': 2, 'cannot': 2, 'recall': 2, 'where': 4, 'do': 3, 'know': 2, 'any': 2, 'boys': 2, 'after': 6, 'an': 5, 'absence': 2, 'some': 4, 'months': 2, 'again': 4, 'feel': 2, 'profound': 2, 'repulsion': 2, 'so': 5, 'latter': 2, 'prevail': 2, 'finally': 4, 'assume': 2, 'part': 3, 'visitor': 3, 'remark': 3, 'insincerely': 2, 'master': 2, 'pleasant': 2, 'see': 3, 'such': 3, 'case': 2, 'picture': 2, 'ancient': 4, 'system': 5, 'floats': 2, 'across': 2, 'field': 3, 'sleeping': 2, 'consciousness': 4, 'dreamer': 5, 'naturally': 2, 'drawn': 2, 'into': 4, 'begins': 3, 'adapt': 2, 'himself': 2, 'its': 2, 'demands': 2, 'does': 2, 'influence': 2, 'other': 5, 'later': 6, 'incompatible': 2, 'unconsciously': 2, 'affect': 2, 'cords': 2, 'connection': 2, 'however': 2, 'awake': 2, 'would': 2, 'enable': 2, 'him': 4, 'adjust': 2, 'critically': 2, 'acting': 2, 'apperception': 2, 'defective': 2, 'outside': 2, 'immediate': 2, 'jostling': 3, 'has': 3, 'come': 3, 'central': 2, 'focus': 2, 'recent': 2, 'causes': 2, 'harmonising': 2, 'modification': 2, 'ceases': 2, 'be': 3, 'boy': 2, 'assumes': 2, 'recently': 3, 'dead': 10, 'friends': 3, 'furnish': 2, 'formed': 2, 'exactly': 2, 'same': 3, 'way': 2, 'these': 5, 'return': 2, 'life': 6, 'only': 2, 'difference': 2, 'they': 5, 'present': 3, 'pronounced': 2, 'poignantly': 2, 'emotional': 3, 'shape': 2, 'partly': 4, 'very': 4, 'subject': 3, 'because': 3, 'fact': 4, 'death': 8, 'definitely': 2, 'divides': 2, 'impressions': 2, 'groups': 2, 'intimately': 2, 'allied': 2, 'each': 2, 'their': 2, 'absolutely': 2, 'opposed': 2, 'one': 5, 'group': 2, 'friend': 16, 'alive': 8, 'proceed': 2, 'series': 3, 'man': 3, 'woman': 2, 'illustrating': 2, 'observation': 3, 'mr': 4, 'c': 4, 'age': 3, 'about': 4, 'twenty': 2, 'eight': 2, 'scientific': 2, 'training': 2, 'aptitudes': 2, 'shortly': 2, 'mother': 5, 's': 2, 'repeatedly': 2, 'dreamed': 6, 'she': 16, 'had': 17, 'been': 9, 'buried': 3, 'was': 24, 'found': 4, 'out': 3, 'really': 3, 'describes': 2, 'painful': 3, 'intellectual': 2, 'struggles': 2, 'went': 4, 'on': 8, 'arguments': 2, 'favour': 2, 'impossibility': 2, 'prolonged': 2, 'grave': 2, 'how': 2, 'doubts': 2, 'were': 2, 'swallowed': 2, 'up': 2, 'wonder': 2, 'joy': 3, 'actually': 2, 'became': 2, 'less': 2, 'frequent': 2, 'occurred': 7, 'isolated': 2, 'clearly': 2, 'shows': 2, 'further': 2, 'stage': 2, 'process': 2, 'father': 2, 'just': 3, 'returned': 3, 'home': 2, 'puzzled': 2, 'make': 2, 'puzzling': 2, 'long': 2, 'asked': 4, 'sister': 2, 'moment': 2, 'flashed': 2, 'thinks': 2, 'relief': 2, 'solution': 2, 'difficulty': 2, 'than': 3, 'grief': 2, 'ii': 2, 'mrs': 10, 'f': 10, 'highly': 2, 'intelligent': 2, 'somewhat': 4, 'temperament': 2, 'week': 2, 'lifelong': 3, 'whom': 4, 'greatly': 2, 'attached': 2, 'first': 2, 'her': 16, 'finding': 3, 'then': 4, 'course': 2, 'discovering': 2, 'second': 2, 'following': 2, 'night': 2, 'imagined': 3, 'bed': 2, 'strange': 2, 'things': 4, 'heard': 2, 'e': 2, 'gave': 3, 'few': 4, 'souvenirs': 2, 'leaving': 2, 'room': 2, 'spoken': 2, 'fourth': 2, 'subsequent': 2, 'date': 3, 'came': 2, 'saying': 2, 'earth': 2, 'minutes': 2, 'give': 2, 'messages': 2, 'assure': 2, 'happy': 2, 'another': 3, 'world': 2, 'enjoyment': 2, 'fullest': 2, 'year': 2, 'brought': 2, 'news': 3, 'still': 3, 'taken': 2, 'said': 2, 'did': 2, 'explain': 2, 'why': 2, 'supposed': 2, 'no': 6, 'questions': 2, 'felt': 3, 'curiosity': 2, 'being': 2, 'absorbed': 2, 'proceeded': 2, 'talk': 2, 'over': 2, 'happened': 2, 'last': 3, 'met': 2, 'natural': 2, 'detailed': 2, 'awaking': 2, 'exhausted': 2, 'although': 2, 'superstitious': 2, 'consolation': 2, 'next': 3, 'observed': 2, 'include': 2, 'all': 2, 'intervals': 2, 'unexpected': 2, 'reached': 2, 'me': 3, 'near': 2, 'recovering': 2, 'attack': 2, 'influenza': 2, 'could': 2, 'connected': 2, 'event': 2, 'until': 2, 'fortnight': 2, 'th': 3, 'january': 2, 'asking': 2, 'clergyman': 2, 'biblical': 2, 'scholar': 2, 'whether': 2, 'opinion': 2, 'jesus': 2, 'able': 2, 'speak': 2, 'greek': 2, 'awoke': 2, 'before': 3, 'received': 2, 'answer': 2, 'sort': 2, 'doubt': 3, 'hesitation': 2, 'surprise': 2, 'aroused': 2, 'appearance': 2, 'nineteen': 2, 'days': 3, 'february': 2, 'gazing': 2, 'postcard': 2, 'good': 2, 'wishes': 2, 'written': 3, 'latin': 2, 'sent': 2, 'actual': 2, 'birthday': 3, 'regretting': 2, 'answered': 2, 'mind': 2, 'letter': 2, 'unable': 2, 'reply': 2, 'those': 2, 'reversals': 2, 'freud': 2, 'others': 2, 'noted': 2, 'uncommon': 2})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#贝叶斯公式 P(c|w) -> P(w|c)P(c)/P(w)\n",
    "# c correct 要纠正的词, w word 输入的词 \n",
    "#求解上面概率公式的最大值，把那个c提示纠正出来\n",
    "#注意：分母可以消掉，因为比较不同的候选词时都是一样的输入词分母，\n",
    "#所以只要比较分子即可。\n",
    "'''\n",
    "\n",
    "#处理词库（随便找一篇英文）\n",
    "#把词拿出来，大小转小写，去掉特输字符，只留a-z\n",
    "def words(text):\n",
    "    return re.findall('[a-z]+',text.lower())\n",
    "\n",
    "\n",
    "#词频统计，即P(c)先验概率\n",
    "#（词频：词出现的次数,频率次数，不是概率，不用除整体的词数）\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda:1)\n",
    "    #lambda 定定一个返回1的匿名函数，给collection.defaultdict\n",
    "    #特征字典功能是指定值并返回\n",
    "    #此处意为指定词频默认设成1，\n",
    "    #避免语料库中不存在的词，出现P(h)是0，结果无效的情况 model +=1累加\n",
    "    #即，词最少出现一次，没出现也算一次\n",
    "    for f in features:\n",
    "        model[f] +=1\n",
    "        \n",
    "    return model\n",
    "\n",
    "#统计全部checkWord.text文件（语料库）中出现的词频（词出现的次数）\n",
    "NWORDS = train(words(open(r'data/checkWord.txt').read()))\n",
    "\n",
    "#打印词频（先验概率P（c））\n",
    "print(NWORDS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面来算P(w|c)\n",
    "#根据 编辑距离（即，使用了几次变换后能从正确词变到输错的那个词，\n",
    "#比如，the输成了tha，只有一个字母错了，那编辑距离就是1\n",
    "#距离越大变换越复杂，说明越不可能，越小的越有可能犯这个错\n",
    "#可能性概率大，为0则表示完全没错，\n",
    "#所以优选编辑距离小越常见错的时候的这个候选词）\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "#==返回一个集合与输入词编辑距离 = 1 的所有词集合==\n",
    "#（即，只变换一次就能输错的这些词，\n",
    "#比如只输入错一个字母e，输入成了a，或多加了一个字母，或多删了一个字母，增删改） \n",
    "\n",
    "def edits1(word):\n",
    "    n = len(word)\n",
    "    return set([word[0:i]+word[i+1:] for i in range(n)]+\n",
    "        [word[0:i]+word[i+1]+word[i]+word[i+2:] for i in range(n-1)]+\n",
    "        [word[0:i]+c+word[i+1:] for i in range(n) for c in alphabet]+\n",
    "         [word[0:i]+c+word[i:] for i in range(n+1) for c in alphabet]\n",
    "        )\n",
    "#第一行：删，遍历词长度,删掉第i位的字符，\n",
    "#左取右不取，i被漏掉了，只留了i之前的和i之后的字母\n",
    "#print('test'[0:1]) #t \n",
    "#print('test'[2:]) #st\n",
    "#上面组合，tst删了第i位\n",
    "#第二行：有一个字母换位了\n",
    "#print('abcdefg'[0:1]+'abcdefg'[2]+'abcdefg'[1]+'abcdefg'[3:])\n",
    "#acbdefg\n",
    "#第三行，写错一个字母，漏掉i，换成c，任意字母了\n",
    "#第三行，多加了一个字母\n",
    "#print(\"==编辑距离为1的词集合==\")\n",
    "#print(edits1('appy'))\n",
    "\n",
    "#编辑距离为2的词集合（在1的基础上再打乱一次，就是距离为2的）\n",
    "def edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "#print(\"==编辑距离为2的词集合==\")\n",
    "#print(edits2('appy'))\n",
    "#{'arpiy', 'hpty', 'appyqy', 'apypg', 'yaspy', 'appywy', 'amppuy', 'cappt', 'qaxppy', 'haapy', 'zppyr', 'appuo', 'appqyq', 'oapdpy', 'apqi', 'azpmpy', 'asppo', 'wppr', 'lakppy', 'axppyu', 'bspy', 'ampzy', 'agpby', 'afkppy', 'mappn', 'nlappy', 'anppyw', 'qappu', 'akkppy', 'valpy', 'dppy', 'alppcy', 'aany', 'xakpy', 'rapqpy', 'xpiy', 'apyty', 'hagpy', 'napepy', 'jfpy', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'any', 'happy', 'away'}\n"
     ]
    }
   ],
   "source": [
    "#测试打印发现编辑复杂度为1和2的有十分多的组合，但大多数都是错的，只有几个词是正确的词\n",
    "#{'any', 'happy', 'away'}\n",
    "#这些集合是我们用来纠正的候选词，所以只需保留正确的，错的过滤掉。\n",
    "\n",
    "#过滤的方法就是保留在语料库中的词\n",
    "#重新定义edits2\n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "print(known_edits2('appy'))#测试发现只保留了正确的候选词，不正确的都过滤掉了\n",
    "#只算编辑距离为1和2的先比较，如果为1的概率大就直接选中即可，不用再去算更不可能的编辑距离3了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==纠正以下输错的词==\n",
      "\n",
      "候选词： {'more'}\n",
      "morw 纠正： more\n",
      "候选词： {'happy', 'all'}\n",
      "appl 纠正： happy\n",
      "候选词： {'the', 'to', 'th', 'two', 'too'}\n",
      "tho 纠正： the\n",
      "候选词： {'something'}\n",
      "somethin 纠正”： something\n"
     ]
    }
   ],
   "source": [
    "#返回在词库中的词的词集合\n",
    "def known(words):\n",
    "    return set(w for w in words if w in NWORDS)\n",
    "#known(['at','of','something','filter'])#{'at', 'of', 'something'}\n",
    "\n",
    "#取NWORDS字典中的v最大值的key\n",
    "def correct(word):\n",
    "    #比较编辑距离为0 为1 为2 \n",
    "    #也即概率P(w|c)（把c输成w的可能性）为0 1 2 时 的 词库中最大词频P(c),\n",
    "    #即两个条件组合P(w|c)*P(c)决定选哪个正确词推荐 \n",
    "    candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "    #known([word])和词本身一致，距离为0;\n",
    "    #known(edits1(word))距离为1的词；\n",
    "    #known_edits2(word)距离为2的词\n",
    "    #[word]不在词库中的词\n",
    "    print(\"候选词：\",candidates)\n",
    "    #有了候选结果选一个最大的就好了\n",
    "    return max(candidates, key = lambda w: NWORDS[w])\n",
    "\n",
    "#max取最大值测试，key在词库中的最大词频\n",
    "#print(\"==静态词测试==\")\n",
    "#max(['at','of','something'],key = lambda w: NWORDS[w])#'of'\n",
    "#print(NWORDS['at'],NWORDS['of'],NWORDS['something'])#7 49 2\n",
    "#print(max({'the', 'to', 'th', 'two', 'too'},key = lambda w: NWORDS[w]))#the\n",
    "#print(NWORDS['the'],NWORDS['to'],NWORDS['th'],NWORDS['two'],NWORDS['too'])#63 35 3 4 2\n",
    "\n",
    "print(\"==纠正以下输错的词（考虑双因素P(w|c)P(c)））==\\n\")\n",
    "print(\"morw 纠正：\",correct('morw'))#more\n",
    "print(\"appl 纠正：\",correct('appl'))#happy\n",
    "print(\"tho 纠正：\",correct('tho'))#the\n",
    "print(\"somethin 纠正”：\",correct('somethin'))#something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==反例：纠正以下输错的词（只考虑单因素P(c)））==\n",
      "\n",
      "morw 纠正： the\n",
      "appl 纠正： the\n",
      "tho 纠正： the\n",
      "somethin 纠正”： the\n"
     ]
    }
   ],
   "source": [
    "#下面看下不考虑P(w|c)正确词和输错词之间概率可能性大小，只考虑P(c)词频大小时的纠正效果\n",
    "def correct_2(word):\n",
    "    candidates_2 = NWORDS\n",
    "    #print(\"候选词2：\",candidates_2)\n",
    "    #以整个词库做了候选词：{'a': 41, 'simple': 2, 'illustration': 3, 'of': 49, 'the': 63, 'clash': 2, 'and': 40, 'confusion': 2, 'two': 4, 'opposing': 4, 'systems': 6, 'memories': 4, 'in': 31, 'dreams': 11, 'when': 4, 'due': 2, 'apperceptive': 2, 'control': 2, 'is': 15, 'lacking': 2, 'supplied': 2, 'by': 7, 'common': 2, 'well': 2, 'recognised': 2\n",
    "    return max(candidates_2, key = lambda w: NWORDS[w])\n",
    "\n",
    "print(\"==反例：纠正以下输错的词（只考虑单因素P(c)））==\\n\")\n",
    "print(\"morw 纠正：\",correct_2('morw'))#more\n",
    "print(\"appl 纠正：\",correct_2('appl'))#happy\n",
    "print(\"tho 纠正：\",correct_2('tho'))#the\n",
    "print(\"somethin 纠正”：\",correct_2('somethin'))#something\n",
    "\n",
    "#结果很显然没有达到纠正的目的，因为它是以整个词库做为候选词了\n",
    "#所以选出来的最大词频肯定是和输入的词是不搭边的，选中了词库中最大词频the推荐了\n",
    "#所在，要在词库众多的词中，找到跟这个错词有关的长的差不多的词，从这些当中选最大词频的才可以\n",
    "#找相关词本例就是通过编辑距离来算的，\n",
    "#距离越小相关度越高，选几个最小的和P(c)在词库中的词频概率相结合就是上文中正确的纠正结果\n",
    "#只考虑P(w|c)呢，也是不行的，那个只是算了可能的词表，脱离了P(c)，它就没有一个词频属性和衡量标准，没有办法比较大小。\n",
    "#所以要P(w|c)P(c)二者结合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1、贝叶斯原理：求逆向概率，通过已经的先验概率求解自然界中的未知概率\n",
    "公式：P（A|B） = P(B|A)P(A)/P(B)\n",
    "比如上例P（c正确词|w输入的错词），我们要求这个输错词条件下是某正词库中的正确词的概率，\n",
    "但这个条件输入的错词，是有各种可能的，我们无法知道。\n",
    "所以求这样的一个未知的概率，就可以通过，P（w|c）P(c)/P(w) 这个公式，\n",
    "转化为求P（w|c）的过程，P(c)是已知的，正确词在词库中的词频，是先验概率。\n",
    "#P（w）输入词在比较同一个词的多个推荐词可能性大小时，都是这同一个输入，所以只需比较分子，分母可以消掉。\n",
    "P（w|c）是可求的，给定条件c正确的词，求输错成w的可能性大小，\n",
    "方法是通过编辑距离（变换复杂度）给出一些侯选c词表，选复杂度最小最可能出错的，\n",
    "再结合每个key对应的 P(c)，正确词在词库中的词频, 选一个最大可能的，来推荐纠正\n",
    "\n",
    "\n",
    "2、朴素贝叶斯：\n",
    "垃圾邮件原理：和拼写检查的应用原理一样，不同的就是它会为每个词做检查，看是否符合垃圾邮件的条件\n",
    "P(h+|D) = P(D|h+)P(h+)/P(D)\n",
    "同样的转换为求P(D|h+)\n",
    "#D是输入的很多词集; h+是垃圾邮件条件\n",
    "P(D|h+) = P(d1,d2,d3...|h+)#很多个输入\n",
    "h+条件同时都出现在每个d里面过于严苛，只要有一个满足就应该是垃圾邮件\n",
    "所以上式可展开为：\n",
    "P(d1|h+)*P(d2|d1,h+)*P(d3|d2,d1,h+)#保留前面词对当前词的影响即可\n",
    "\n",
    "朴素贝叶斯（也叫简单贝叶斯simple...）与贝叶斯的区别就是：\n",
    "假设每一个特征d都是独立的，d1与d2 d2与d3之间的影响是不存在的。\n",
    "所以上式不需考虑d2|d1 只考虑d2， d3|d2只考虑d3即可。\n",
    "化简为：\n",
    "P(d1|h+)*P(d2|h+)*P(d3|h+)\n",
    "#每一个输入词是垃圾代入总式\n",
    "P(h+|D) = P(D|h+)P(h+)/P(D)\n",
    "即可算出整个邮件是垃圾邮件的概率\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
